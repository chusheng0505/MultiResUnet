{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.activations import *\n",
    "from tensorflow.keras.regularizers import *\n",
    "from tensorflow.keras import Input\n",
    "\n",
    "from typing import Union , Tuple , Dict , List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "References :\n",
    "1. https://arxiv.org/abs/2010.11929\n",
    "'''\n",
    "def conv_bn(input_tensors: tf.float32,\n",
    "            filters: int,\n",
    "            kernel_size: Tuple[int],\n",
    "            activation: str = 'relu',\n",
    "            padding: str = 'same') -> tf.float32:\n",
    "    x = Conv2D(filters=filters,\n",
    "               kernel_size=kernel_size,\n",
    "               activation=activation,\n",
    "               padding=padding)(input_tensors)\n",
    "    return x\n",
    "\n",
    "\n",
    "def conv2dTrans_bn(input_tensors: tf.float32,\n",
    "                   filters: int,\n",
    "                   kernel_size: Tuple[int],\n",
    "                   activation: str = 'relu',\n",
    "                   padding: str = 'same') -> tf.float32:\n",
    "    x = Conv2DTranspose(filters=filters,\n",
    "                        kernel_size=kernel_size,\n",
    "                        activation=activation,\n",
    "                        padding=padding)(input_tensors)\n",
    "    return x\n",
    "\n",
    "\n",
    "def ResPath(input_tensors: tf.float32,\n",
    "            filters: int,\n",
    "            n_repeats: int,\n",
    "            activation: str = 'relu',\n",
    "            padding: str = 'same') -> tf.float32:\n",
    "\n",
    "    '''\n",
    "    ResPath : is used to replace traditional skip connection in Unet\n",
    "\n",
    "    It is a combination of two conv2D layers with filter 3x3 and 1x1 respectively\n",
    "    and repeating the combinations in [4,3,2,1] times\n",
    "\n",
    "    @params : n_repeats : nums of replicating of combinations\n",
    "    ---> replicating Add{ conv2d(3x3) , conv2d(1x1) } in several times\n",
    "    '''\n",
    "\n",
    "    def conv(input_tensors: tf.float32,\n",
    "             filters: int,\n",
    "             activation: str = 'relu',\n",
    "             padding: str = 'same'):\n",
    "        conv_3x3 = conv_bn(input_tensors=input_tensors,\n",
    "                           filters=filters,\n",
    "                           kernel_size=(3, 3),\n",
    "                           activation=activation,\n",
    "                           padding=padding)\n",
    "\n",
    "        conv_1x1 = conv_bn(input_tensors=input_tensors,\n",
    "                           filters=filters,\n",
    "                           kernel_size=(1, 1),\n",
    "                           activation=activation,\n",
    "                           padding=padding)\n",
    "        return Add()([conv_3x3, conv_1x1])\n",
    "\n",
    "    x = input_tensors\n",
    "    for _ in range(n_repeats):\n",
    "        x = conv(input_tensors=x,\n",
    "                 filters=filters,\n",
    "                 activation=activation,\n",
    "                 padding=padding)\n",
    "    return x\n",
    "\n",
    "\n",
    "def num_feature_maps(num_features: int,\n",
    "                     alpha: float) -> int:\n",
    "    '''\n",
    "    num_features : numbers of feature maps in U-net , [64,128,256,512]\n",
    "    decrease_rate : propose in paper , [6,3,2] are proposed in paper\n",
    "    @output : floor(alpha * num_features / decrease_rate)\n",
    "    '''\n",
    "    return int(alpha * num_features)\n",
    "\n",
    "\n",
    "\n",
    "def ResBlock(input_tensors: tf.float32,\n",
    "             filters: int,\n",
    "             activation: str = 'relu',\n",
    "             padding: str = 'same') -> tf.float32:\n",
    "\n",
    "    \"\"\"\n",
    "    ResBolck is used to replace the conv2d layers in Unet\n",
    "    It is combinations of three differences kernel_size conv2D layers in parallel -> concat( 3x3 , 5x5 , 7x7)\n",
    "    or it can be simplified by concat. of three conv2D with kernel_size 3x3 and added a residual connection (conv2D with kernel_size 1x1)\n",
    "    --->  ResBlock : concat{three conv2D 3x3} + conv2D(input_tensor,with kernel_size 1x1) or concat( 3x3 , 5x5 , 7x7)\n",
    "\n",
    "    \"\"\"\n",
    "    x = input_tensors\n",
    "    decrease_rate = [0.167, 0.333, 0.5]\n",
    "    result = []\n",
    "    for idx in range(len(decrease_rate)):\n",
    "        n_filters = num_feature_maps(num_features=filters,\n",
    "                                     alpha=decrease_rate[idx])\n",
    "        x = conv_bn(input_tensors=x,\n",
    "                    filters=n_filters,\n",
    "                    kernel_size=(3, 3),\n",
    "                    activation='relu',\n",
    "                    padding=padding)\n",
    "        result.append(x)\n",
    "\n",
    "    n_filters = sum([int(filters * decrease_rate[idx])\n",
    "                    for idx in range(len(decrease_rate))])\n",
    "    x4 = conv_bn(input_tensors=input_tensors,\n",
    "                 filters=n_filters,\n",
    "                 kernel_size=(1, 1),\n",
    "                 activation='relu',\n",
    "                 padding=padding) \n",
    "\n",
    "    x = Concatenate(axis=-1)(result)\n",
    "    output = Add()([x, x4])\n",
    "    output = Activation('relu')(output)\n",
    "    return BatchNormalization()(output)\n",
    "\n",
    "\n",
    "\n",
    "def MultiResUnet(height: int,\n",
    "                 width: int,\n",
    "                 color_channels: int,\n",
    "                 num_classes: int) -> tf.float32:\n",
    "    input_shape = (height, width, color_channels)\n",
    "    inputs = Input(shape=input_shape)\n",
    "    out = conv_bn(input_tensors=inputs,\n",
    "                  filters=32,\n",
    "                  kernel_size=(3, 3),\n",
    "                  activation='relu',\n",
    "                  padding='same') \n",
    "\n",
    "    pooling_result = []\n",
    "    for n in range(5):\n",
    "        x = ResBlock(input_tensors=out,\n",
    "                     filters=32 * 2**n,\n",
    "                     activation='relu',\n",
    "                     padding='same')\n",
    "        out = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "        pooling_result.append(out)\n",
    "\n",
    "    pooling_result = pooling_result[::-1][1:]\n",
    "    for idx in range(len(pooling_result)):\n",
    "        n_filters = pooling_result[idx].shape[-1]\n",
    "        x_1 = conv2dTrans_bn(input_tensors=x,\n",
    "                             filters=n_filters,\n",
    "                             kernel_size=(2, 2),\n",
    "                             activation='relu',\n",
    "                             padding='same')\n",
    "        x_2 = ResPath(input_tensors=pooling_result[idx],\n",
    "                      filters=n_filters,\n",
    "                      n_repeats=idx + 1,\n",
    "                      activation='relu',\n",
    "                      padding='same')\n",
    "        x = Concatenate()([x_1, x_2])\n",
    "        x = UpSampling2D()(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    output = conv_bn(input_tensors=x,\n",
    "                     filters=num_classes,\n",
    "                     kernel_size=(1, 1),\n",
    "                     activation='softmax',\n",
    "                     padding='same')\n",
    "    return Model(inputs=inputs, outputs=output, name='MultiResUnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
